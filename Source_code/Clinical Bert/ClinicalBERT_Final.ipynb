{"cells":[{"cell_type":"code","execution_count":null,"id":"b1932f9e-42ba-44bb-aff0-1a946f1a9f7d","metadata":{"id":"b1932f9e-42ba-44bb-aff0-1a946f1a9f7d","outputId":"1a721cea-b1a3-4c33-a753-2c24201ec835"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n","  Downloading huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.2)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Collecting regex!=2019.12.17 (from transformers)\n","  Downloading regex-2024.5.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.20,>=0.19 (from transformers)\n","  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting safetensors>=0.4.1 (from transformers)\n","  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n","Downloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading regex-2024.5.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (774 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.1/774.1 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.23.0 regex-2024.5.10 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.40.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"id":"4e05b09d-ff06-49ec-8168-366f6c82873e","metadata":{"id":"4e05b09d-ff06-49ec-8168-366f6c82873e","outputId":"c3f268e6-aa06-4a8c-f2a5-a9e58a9c8c42"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting scikit-learn\n","  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.2)\n","Collecting scipy>=1.6.0 (from scikit-learn)\n","  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n","  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n","Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n","  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n","Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n","Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n","Successfully installed joblib-1.4.2 scikit-learn-1.4.2 scipy-1.13.0 threadpoolctl-3.5.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install scikit-learn"]},{"cell_type":"code","execution_count":null,"id":"6aa237e1-dad3-41bd-95fa-f2798f02fb27","metadata":{"id":"6aa237e1-dad3-41bd-95fa-f2798f02fb27","outputId":"f305739d-9d08-43c5-a98a-8917ef258669"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pandas\n","  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n","Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n","Collecting tzdata>=2022.7 (from pandas)\n","  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tzdata, pandas\n","Successfully installed pandas-2.2.2 tzdata-2024.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install pandas"]},{"cell_type":"code","execution_count":null,"id":"929abf44-70fd-4542-aa77-d1572e85b598","metadata":{"id":"929abf44-70fd-4542-aa77-d1572e85b598","outputId":"c9f3a43b-a8b4-4c04-aba6-e0ba3f51760b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting imbalanced-learn\n","  Downloading imbalanced_learn-0.12.2-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.26.2)\n","Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.13.0)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.4.2)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (3.5.0)\n","Downloading imbalanced_learn-0.12.2-py3-none-any.whl (257 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.0/258.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: imbalanced-learn\n","Successfully installed imbalanced-learn-0.12.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install imbalanced-learn\n"]},{"cell_type":"code","execution_count":null,"id":"743a8ccc-b58e-4c51-90ea-707dd1da7d46","metadata":{"id":"743a8ccc-b58e-4c51-90ea-707dd1da7d46"},"outputs":[],"source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score\n","import pandas as pd\n","from imblearn.over_sampling import RandomOverSampler"]},{"cell_type":"code","execution_count":null,"id":"559df56b-9943-4725-bc75-eafe5fda9c60","metadata":{"id":"559df56b-9943-4725-bc75-eafe5fda9c60","outputId":"e709c828-caa8-4d0c-bec4-32e48e3bb45b"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["MAX_LEN = 128\n","BATCH_SIZE = 16\n","EPOCHS = 3\n","LEARNING_RATE = 2e-5\n","\n","tokenizer = BertTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n","model = BertForSequenceClassification.from_pretrained('emilyalsentzer/Bio_ClinicalBERT', num_labels=2)  # 2 classes: Not readmitted, Readmitted\n"]},{"cell_type":"code","execution_count":null,"id":"207c55b0-ee19-4fc4-ac2e-22176479b956","metadata":{"id":"207c55b0-ee19-4fc4-ac2e-22176479b956"},"outputs":[],"source":["model_df = pd.read_csv(\"model_data.csv\")\n","\n","model_df = model_df.drop_duplicates(subset=['SUBJECT_ID'], keep='first')\n","\n","num_records_before_sampling = len(model_df)"]},{"cell_type":"code","execution_count":null,"id":"5cde13ef-0ca7-4737-98ee-ac781f9e0505","metadata":{"id":"5cde13ef-0ca7-4737-98ee-ac781f9e0505","outputId":"9c3b7dc3-76cc-4fc2-df91-044003748289"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of records before sampling: 41965\n","Number of records after sampling: 81308\n"]}],"source":["ros = RandomOverSampler(random_state=42)\n","train_texts_reshaped = model_df['TEXT'].values.reshape(-1, 1)\n","train_texts_balanced, train_labels_balanced = ros.fit_resample(train_texts_reshaped, model_df['readmitted'])\n","model_df_balanced = pd.DataFrame({'TEXT': train_texts_balanced.squeeze(), 'readmitted': train_labels_balanced})\n","\n","num_records_after_sampling = len(model_df_balanced)\n","\n","print(\"Number of records before sampling:\", num_records_before_sampling)\n","print(\"Number of records after sampling:\", num_records_after_sampling)"]},{"cell_type":"code","execution_count":null,"id":"3f25222a-6116-432f-9989-409f6859e345","metadata":{"id":"3f25222a-6116-432f-9989-409f6859e345","outputId":"ac1deea7-e80f-4695-9566-c4ba12ab180b"},"outputs":[{"name":"stdout","output_type":"stream","text":["readmitted\n","0    40654\n","1    40654\n","Name: count, dtype: int64\n"]}],"source":["unique_counts = model_df_balanced[\"readmitted\"].value_counts()\n","print(unique_counts)"]},{"cell_type":"code","execution_count":null,"id":"2647d610-6cbb-4c6b-b4a0-55e2c8a67c48","metadata":{"id":"2647d610-6cbb-4c6b-b4a0-55e2c8a67c48"},"outputs":[],"source":["train_texts, test_texts, train_labels, test_labels = train_test_split(model_df_balanced['TEXT'], model_df_balanced['readmitted'], test_size=0.3, random_state=42)\n","val_texts, test_texts, val_labels, test_labels = train_test_split(test_texts, test_labels, test_size=0.5, random_state=42)\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = str(self.texts.iloc[idx])\n","        label = self.labels.iloc[idx]\n","\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            truncation=True,\n","            return_token_type_ids=True\n","        )\n","\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","\n","        return {\n","            'input_ids': torch.tensor(ids, dtype=torch.long),\n","            'attention_mask': torch.tensor(mask, dtype=torch.long),\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","train_dataset = CustomDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","val_dataset = CustomDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","test_dataset = CustomDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","execution_count":null,"id":"5fd01c4d-c7d6-45c8-aefc-2fe5d9feeaeb","metadata":{"id":"5fd01c4d-c7d6-45c8-aefc-2fe5d9feeaeb","outputId":"30e5bb46-462b-4196-a4c0-33aa97748793"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3, Validation Accuracy: 0.9678583142013775\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.94      0.97      6184\n","           1       0.94      1.00      0.97      6012\n","\n","    accuracy                           0.97     12196\n","   macro avg       0.97      0.97      0.97     12196\n","weighted avg       0.97      0.97      0.97     12196\n","\n","Epoch 2/3, Validation Accuracy: 0.9812233519186618\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.96      0.98      6184\n","           1       0.96      1.00      0.98      6012\n","\n","    accuracy                           0.98     12196\n","   macro avg       0.98      0.98      0.98     12196\n","weighted avg       0.98      0.98      0.98     12196\n","\n","Epoch 3/3, Validation Accuracy: 0.9803214168579862\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.96      0.98      6184\n","           1       0.96      1.00      0.98      6012\n","\n","    accuracy                           0.98     12196\n","   macro avg       0.98      0.98      0.98     12196\n","weighted avg       0.98      0.98      0.98     12196\n","\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","for epoch in range(EPOCHS):\n","    model.train()\n","    for batch in train_loader:\n","        try:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs.loss\n","            loss.backward()\n","            optimizer.step()\n","\n","        except Exception as e:\n","            print(f\"Error occurred in training loop: {e}. Skipping this batch.\")\n","            continue\n","\n","    model.eval()\n","    val_preds = []\n","    val_true = []\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            try:\n","                input_ids = batch['input_ids'].to(device)\n","                attention_mask = batch['attention_mask'].to(device)\n","                labels = batch['labels'].to(device)\n","\n","                outputs = model(input_ids, attention_mask=attention_mask)\n","                _, preds = torch.max(outputs.logits, dim=1)\n","\n","                val_preds.extend(preds.tolist())\n","                val_true.extend(labels.tolist())\n","\n","            except Exception as e:\n","                print(f\"Error occurred in evaluation loop: {e}. Skipping this batch.\")\n","                continue\n","\n","    val_acc = accuracy_score(val_true, val_preds)\n","    val_report = classification_report(val_true, val_preds)\n","\n","    print(f\"Epoch {epoch+1}/{EPOCHS}, Validation Accuracy: {val_acc}\")\n","    print(val_report)"]},{"cell_type":"code","execution_count":null,"id":"7a5bc3e8-6e8f-4dc1-8454-21ea036d5130","metadata":{"id":"7a5bc3e8-6e8f-4dc1-8454-21ea036d5130"},"outputs":[],"source":["import pickle\n","\n","filename = 'BERT_model_final.pkl'\n","\n","with open(filename, 'wb') as file:\n","    pickle.dump(model, file)"]},{"cell_type":"code","execution_count":null,"id":"9f0181ba-0768-454a-afa1-17691f008b7b","metadata":{"id":"9f0181ba-0768-454a-afa1-17691f008b7b"},"outputs":[],"source":["import pickle\n","\n","def tokenize_and_convert(data_loader):\n","    tokenized_data = []\n","    for batch in data_loader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        tokenized_batch = {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'labels': labels\n","        }\n","        tokenized_data.append(tokenized_batch)\n","    return tokenized_data\n","\n","train_tokenized = tokenize_and_convert(train_loader)\n"]},{"cell_type":"code","execution_count":null,"id":"6f641c6b-c38a-4226-b7e8-64a63512735b","metadata":{"id":"6f641c6b-c38a-4226-b7e8-64a63512735b"},"outputs":[],"source":["test_tokenized = tokenize_and_convert(test_loader)"]},{"cell_type":"code","execution_count":null,"id":"f17ab771-32e4-4d2c-957b-41d37028d143","metadata":{"id":"f17ab771-32e4-4d2c-957b-41d37028d143"},"outputs":[],"source":["val_tokenized = tokenize_and_convert(val_loader)"]},{"cell_type":"code","execution_count":null,"id":"4b87264a-5fa1-4528-9c55-19e3c1c6c3cd","metadata":{"id":"4b87264a-5fa1-4528-9c55-19e3c1c6c3cd"},"outputs":[],"source":["all_tokenized = train_tokenized + test_tokenized + val_tokenized"]},{"cell_type":"code","execution_count":null,"id":"136e3798-ca55-4853-a3ea-1e281d389a01","metadata":{"id":"136e3798-ca55-4853-a3ea-1e281d389a01"},"outputs":[],"source":["with open(\"tokenizedBERT.pkl\", \"wb\") as f:\n","    pickle.dump(all_tokenized, f)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}